{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad1353b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학번을 입력하세요 : 18\n",
      "학년을 입력하세요 : 1\n",
      "가장 선호하는 전공교수님을 입력하세요 : 최재영\n",
      "가장 선호하지 않는 전공교수님을 입력하세요 : 이상웅\n",
      "           교수성명\n",
      "0              \n",
      "2           한명묵\n",
      "3           정윤현\n",
      "4           차영운\n",
      "5            김원\n",
      "7           최아영\n",
      "8        정윤현차영운\n",
      "9        정윤현한명묵\n",
      "10        김원차영운\n",
      "11        정윤현김원\n",
      "12       한명묵차영운\n",
      "13    정윤현차영운한명묵\n",
      "14          정옥란\n",
      "15          김철연\n",
      "16        한명묵김원\n",
      "17     정윤현김원차영운\n",
      "18     정윤현김원한명묵\n",
      "19          정용주\n",
      "20       한명묵정윤현\n",
      "22           민홍\n",
      "23       정윤현최아영\n",
      "24  정윤현김원한명묵차영운\n",
      "25        정윤현민홍\n",
      "26     한명묵김원차영운\n",
      "27          최기호\n",
      "28       김철연최아영\n",
      "29          노웅기\n",
      "30       정윤현김철연\n",
      "31          오영민\n",
      "32          조정찬\n",
      "33    한명묵김철연정윤현\n",
      "34       한명묵김철연\n",
      "36    한명묵정윤현최아영\n",
      "37        민홍최아영\n",
      "38       차영운최아영\n",
      "39       한명묵최아영\n",
      "40       최기호강상우\n",
      "41        차영운민홍\n",
      "42          강상우\n",
      "                     교과명                  교수성명    점수\n",
      "31                  확률통계                   최아영  91.5\n",
      "5                   로봇공학                   정용주  93.8\n",
      "34  Practical English A2       Lawrence Minton  97.5\n",
      "43  Practical English B2            Hannah Yoo  96.6\n",
      "69  Practical English D2  Sarah Jane Beresford  96.2\n",
      "60  Practical English C2       Portia Fay Gray  94.3\n",
      "12             소프트웨어구현패턴                   이주형  94.0\n",
      "74               과학기술글쓰기                   박성지  83.4\n"
     ]
    }
   ],
   "source": [
    "import mlxtend\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import datetime as dt\n",
    "\n",
    "date = dt.datetime.now()\n",
    "if int(date.month)>7:\n",
    "    semester=2\n",
    "else:\n",
    "    semester=1\n",
    "    \n",
    "SW=pd.read_excel('C:/Users/USer\\Desktop/졸업작품/18-2 소웨 전공.xls')\n",
    "\n",
    "student_ID=int(input('학번을 입력하세요 : '))\n",
    "year=int(input('학년을 입력하세요 : '))\n",
    "if year==3 or year==4 :\n",
    "    track=str(input('어떤 트랙을 수강하고 계시는지 입력하세요(빅데이터/일반/IOT/보안) : '))\n",
    "    \n",
    "fav_pro=str(input('가장 선호하는 전공교수님을 입력하세요 : '))\n",
    "hate_pro=str(input('가장 선호하지 않는 전공교수님을 입력하세요 : '))\n",
    "fav_pro30=fav_pro+\"30\"\n",
    "fav_pro20=fav_pro+\"20\"\n",
    "\n",
    "hate_pro0=hate_pro+\"0\"\n",
    "hate_pro_minus=hate_pro+'-'\n",
    "\n",
    "\n",
    "data_df=pd.read_csv('C:/Users/USer/Desktop/졸업작품/졸작수강기록.csv')\n",
    "with open('C:/Users/USer/Desktop/졸업작품/졸작수강기록.csv') as myfile:\n",
    "    total_lines = sum(1 for line in myfile)\n",
    "    \n",
    "class MatrixFactorization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "\n",
    "        # init latent features\n",
    "        self._P = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._Q = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # init biases\n",
    "        self._b_P = np.zeros(self._num_users)\n",
    "        self._b_Q = np.zeros(self._num_items)\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            xi, yi = self._R.nonzero()\n",
    "            for i, j in zip(xi, yi):\n",
    "                self.gradient_descent(i, j, self._R[i, j])\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        xi, yi = self._R.nonzero()\n",
    "        # predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "        return dp, dq\n",
    "\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
    "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
    "\n",
    "        # update latent feature\n",
    "        dp, dq = self.gradient(error, i, j)\n",
    "        self._P[i, :] += self._learning_rate * dp\n",
    "        self._Q[j, :] += self._learning_rate * dq\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
    "\n",
    "        - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)\n",
    "\n",
    "\n",
    "\n",
    "# run example\n",
    "if __name__ == \"__main__\":\n",
    "    R = data_df.to_numpy()\n",
    "    \n",
    "factorizer = MatrixFactorization(R, k=3, learning_rate=0.01, reg_param=0.01, epochs=1000, verbose=False)\n",
    "factorizer.fit()\n",
    "result=factorizer.get_complete_matrix()\n",
    "\n",
    "result_df=pd.DataFrame(result)\n",
    "result_df.columns=[\"한명묵\",\"정용주\",\"최아영\",\"민연아\",\"강상우\",\"이주형\",\"노웅기\",\"최재영\",\"정옥란\",\"황효석\",\"이상웅\",\"유준\",\"최재혁\",\"조정찬\",\"김원\",\"최기호\",\"정윤현\",\"민홍\",\"오영민\",\"차영운\",\"김철연\",\"전영철\"]\n",
    "result_df=(result_df*15).round(-1).astype(int)\n",
    "\n",
    "result_df['한명묵']=result_df['한명묵'].map('한명묵{}'.format)\n",
    "result_df['정용주']=result_df['정용주'].map('정용주{}'.format)\n",
    "result_df['최아영']=result_df['최아영'].map('최아영{}'.format)\n",
    "result_df['민연아']=result_df['민연아'].map('민연아{}'.format)\n",
    "result_df['강상우']=result_df['강상우'].map('강상우{}'.format)\n",
    "\n",
    "result_df['이주형']=result_df['이주형'].map('이주형{}'.format)\n",
    "result_df['노웅기']=result_df['노웅기'].map('노웅기{}'.format)\n",
    "result_df['최재영']=result_df['최재영'].map('최재영{}'.format)\n",
    "result_df['정옥란']=result_df['정옥란'].map('정옥란{}'.format)\n",
    "result_df['황효석']=result_df['황효석'].map('황효석{}'.format)\n",
    "\n",
    "result_df['이상웅']=result_df['이상웅'].map('이상웅{}'.format)\n",
    "result_df['유준']=result_df['유준'].map('유 준{}'.format)\n",
    "result_df['최재혁']=result_df['최재혁'].map('최재혁{}'.format)\n",
    "result_df['조정찬']=result_df['조정찬'].map('조정찬{}'.format)\n",
    "result_df['김원']=result_df['김원'].map('김 원{}'.format)\n",
    "\n",
    "result_df['최기호']=result_df['최기호'].map('최기호{}'.format)\n",
    "result_df['정윤현']=result_df['정윤현'].map('정윤현{}'.format)\n",
    "result_df['민홍']=result_df['민홍'].map('민 홍{}'.format)\n",
    "result_df['오영민']=result_df['오영민'].map('오영민{}'.format)\n",
    "result_df['차영운']=result_df['차영운'].map('차영운{}'.format)\n",
    "\n",
    "result_df['김철연']=result_df['김철연'].map('김철연{}'.format)\n",
    "result_df['전영철']=result_df['전영철'].map('전영철{}'.format)\n",
    "result_df.to_csv('C:/Users/USer/Desktop/졸업작품/sgd.csv',header=False,index=False,encoding='utf-8-sig')\n",
    "sgd_df=pd.read_csv('C:/Users/USer/Desktop/졸업작품/sgd.csv')\n",
    "sgd_df.columns=[\"한명묵\",\"정용주\",\"최아영\",\"민연아\",\"강상우\",\"이주형\",\"노웅기\",\"최재영\",\"정옥란\",\"황효석\",\"이상웅\",\"유준\",\"최재혁\",\"조정찬\",\"김원\",\"최기호\",\"정윤현\",\"민홍\",\"오영민\",\"차영운\",\"김철연\",\"전영철\"]\n",
    "sgd_np=sgd_df.to_numpy()\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(sgd_np).transform(sgd_np)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "fp=fpgrowth(df, min_support=0.2,use_colnames=True)\n",
    "result_fp=pd.DataFrame(fp)\n",
    "result_fp.to_csv('C:/Users/USer/Desktop/졸업작품/fp.csv',header=False,index=False,encoding='utf-8-sig')\n",
    "\n",
    "relation=pd.read_csv('C:/Users/USer/Desktop/졸업작품/fp.csv')\n",
    "\n",
    "#relation.rename(columns={relation.columns[0]:\"support\", relation.columns[1]:'itemsets'},inplace=True)\n",
    "relation.columns=['support','itemsets']\n",
    "\n",
    "condition20=relation[relation['itemsets'].str.contains(fav_pro20)]\n",
    "condition30=relation[relation['itemsets'].str.contains(fav_pro30)]\n",
    "fav=pd.concat([condition20,condition30])\n",
    "fav=fav.sort_values(by=['support'],axis=0,ascending=False)\n",
    "SW_year=SW['수강학년']==year\n",
    "search=SW[SW_year]\n",
    "lecture=search[['교과명','교수성명','점수']]\n",
    "\n",
    "# 피하고싶은 교수님을 데이터프레임에서 제거\n",
    "fav = fav[~fav['itemsets'].str.contains(hate_pro, na=False, case=False)]\n",
    "fav = fav[~fav['itemsets'].str.contains('-', na=False, case=False)]\n",
    "\n",
    "# 학과에 안계신 교수님들 데이터프레임에서 제거\n",
    "lecture = lecture[~lecture['교수성명'].str.contains('황효석', na=False, case=False)]\n",
    "lecture = lecture[~lecture['교수성명'].str.contains('민연아', na=False, case=False)]\n",
    "\n",
    "recommend=[]\n",
    "for item in fav['itemsets']:\n",
    "    if fav_pro in item:\n",
    "        item = item.replace('0',\"\")\n",
    "        item = item.replace('2',\"\")\n",
    "        item = item.replace('3',\"\")\n",
    "        item = item.replace('1',\"\")\n",
    "        item = item.replace('4',\"\")\n",
    "        item = item.replace(fav_pro,\"\")\n",
    "        item=item.replace('frozenset({\\'','')\n",
    "        item=item.replace('\\', \\'\\'})','')\n",
    "        item=item.replace('\\'})','')\n",
    "        item=item.replace('\\'','')\n",
    "        item=item.replace(', ','')\n",
    "        item=item.replace(' ','')\n",
    "        recommend.append(item)\n",
    "\n",
    "count=0\n",
    "final=pd.DataFrame()\n",
    "recommend=pd.DataFrame(recommend)\n",
    "recommend.drop_duplicates(subset=None, keep='first', inplace=True, ignore_index=False)\n",
    "recommend.dropna(inplace=True)\n",
    "recommend.columns=['교수성명']\n",
    "copy=lecture.copy()\n",
    "copy.drop_duplicates(['교과명'], keep='first', inplace=True, ignore_index=False)\n",
    "num_prolec=len(copy)\n",
    "\n",
    "# 선호하는 교수님이 있다면 그 교수님의 강의를 무조건 추천\n",
    "final=pd.concat([final,lecture[lecture['교수성명'].str.contains(fav_pro)]])\n",
    "\n",
    "for pro in recommend['교수성명']:\n",
    "    for prof in lecture['교수성명']:\n",
    "        if pro==prof and count!=num_prolec:\n",
    "            final=pd.concat([final,lecture[lecture['교수성명'].str.contains(prof)]])\n",
    "            count=count+1\n",
    "            continue\n",
    "\n",
    "final.drop_duplicates(['교과명'], keep='first', inplace=True, ignore_index=False)\n",
    "\n",
    "for lec1 in final['교과명']:\n",
    "    for lec2 in lecture['교과명']:\n",
    "        if lec1==lec2 :\n",
    "            lecture = lecture[~lecture['교과명'].str.contains(lec1, na=False, case=False)]\n",
    "            \n",
    "lecture=lecture.sort_values(by=['점수'],axis=0,ascending=False)\n",
    "lecture.drop_duplicates(['교과명'], keep='first', inplace=True, ignore_index=False)\n",
    "final=pd.concat([final,lecture])\n",
    "\n",
    "print(recommend)\n",
    "print(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a82954a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
